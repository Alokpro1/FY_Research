{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score, roc_curve, auc,\\\n",
    "precision_score\n",
    "from sklearn import svm\n",
    "import scipy.io as spio\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "\n",
    "    def __init__(self,kernel='linear',learning_rate=0.001, lambda_param=0.01, n_iters=2,batch_size=256):\n",
    "        self.lr = learning_rate\n",
    "        self.kernel=kernel\n",
    "        self.lambda_param = lambda_param\n",
    "        self.n_iters = n_iters\n",
    "        self.batch_size=batch_size\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "\n",
    "\n",
    "    def train_and_evaluate(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        y_ = np.where(y <= 0, -1, 1)\n",
    "        \n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0\n",
    "\n",
    "        for i in range(self.n_iters):\n",
    "            print('iteration:',i,'/',self.n_iters,'..............')\n",
    "            for idx, x_i in enumerate(X):\n",
    "                condition = (y_[idx] * np.dot(x_i,self.w.T) - self.b) >= 1\n",
    "                if condition:\n",
    "                    self.w -= self.lr * (2 * self.lambda_param * self.w)\n",
    "                else:\n",
    "                    self.w -= self.lr * (2 * self.lambda_param * self.w - np.dot(x_i, y_[idx]))\n",
    "                    self.b -= self.lr * y_[idx]\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        approx = np.dot(X, self.w) - self.b\n",
    "        return np.sign(approx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data):\n",
    "    data_new = data.copy() \n",
    "    data_new[\"type1\"] = np.nan\n",
    "\n",
    "\n",
    "    data_new.loc[data.nameOrig.str.contains('C') & data.nameDest.str.contains('C'),\"type1\"] = \"CC\" \n",
    "    data_new.loc[data.nameOrig.str.contains('C') & data.nameDest.str.contains('M'),\"type1\"] = \"CM\"\n",
    "    data_new.loc[data.nameOrig.str.contains('M') & data.nameDest.str.contains('C'),\"type1\"] = \"MC\"\n",
    "    data_new.loc[data.nameOrig.str.contains('M') & data.nameDest.str.contains('M'),\"type1\"] = \"MM\"\n",
    "    \n",
    "    data_new = data_new.drop('type1',1)\n",
    "    \n",
    "    data_new = data_new[(data_new[\"type\"] == \"CASH_OUT\") | (data_new[\"type\"] == \"TRANSFER\")]\n",
    "    \n",
    "    data_new[\"errorBalanceOrg\"] = data_new.newbalanceOrig + data_new.amount - data_new.oldbalanceOrg\n",
    "    data_new[\"errorBalanceDest\"] = data_new.oldbalanceDest + data_new.amount - data_new.newbalanceDest\n",
    "    \n",
    "    # getting rid of nameOrig and nameDest column.\n",
    "    names = [\"nameOrig\",\"nameDest\"]\n",
    "    data_new = data_new.drop(names,1)\n",
    "    \n",
    "    # dropping isFlaggedFraud column from the fraud,valid, and new_data datasets\n",
    "    data_new = data_new.drop(\"isFlaggedFraud\",1)\n",
    "    \n",
    "    dataset1 = data_new.copy()\n",
    "\n",
    "\n",
    "    # adding feature HourOfDay to Dataset1 \n",
    "    dataset1[\"HourOfDay\"] = np.nan \n",
    "    dataset1.HourOfDay = data_new.step % 24\n",
    "    \n",
    "    # finalizing dataset\n",
    "    dataset = dataset1.copy() # unchanged dataset1\n",
    "    \n",
    "    # getting one-hot encoding of the 'type' variable\n",
    "    dataset = pd.get_dummies(dataset,prefix=['type'])\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading dataset...\n"
     ]
    }
   ],
   "source": [
    "print(\"reading dataset...\")\n",
    "# read data in pandas (pd) data frame\n",
    "data = pd.read_csv(\"../input/PS_20174392719_1491204439457_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying feature engineering...\n"
     ]
    }
   ],
   "source": [
    "print(\"applying feature engineering...\")\n",
    "dataset=feature_engineering(data)\n",
    "# put features & outputs in different data frames\n",
    "Y = dataset.loc[:, 'isFraud']\n",
    "X = dataset.drop(\"isFraud\",1)\n",
    "Y = np.where(Y == 0, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, -1, ...,  1,  1,  1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting dataset into train and test sets...\n"
     ]
    }
   ],
   "source": [
    "print(\"splitting dataset into train and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training started...\n",
      "iteration: 0 / 1 ..............\n",
      "training finished.\n",
      "weights are: [-5.21137922e+02  3.42779711e+03  1.27890127e+04 -1.20737489e+04\n",
      "  1.80116529e+04 -5.61695333e+02 -2.14349646e+04  2.20011454e+04\n",
      " -1.26611084e+01 -6.89355108e-01 -1.13650857e-01]\n"
     ]
    }
   ],
   "source": [
    "print(\"training started...\")\n",
    "clf = SVM(n_iters=1)\n",
    "clf.train_and_evaluate(X.to_numpy(), Y)\n",
    "print(\"training finished.\")\n",
    "print(\"weights are: {}\".format(clf.w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_SVM = confusion_matrix(y_test,predictions)\n",
    "CR_SVM = classification_report(y_test,predictions)\n",
    "fpr, recall, thresholds = roc_curve(y_test, predictions)\n",
    "AUC_SVM = auc(fpr, recall)\n",
    "\n",
    "results = {\"Confusion Matrix\":CM_SVM,\"Classification Report\":CR_SVM,\"Area Under Curve\":AUC_SVM}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[111859 440577]\n",
      " [     7   1639]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.20      0.34    552436\n",
      "           1       0.00      1.00      0.01      1646\n",
      "\n",
      "    accuracy                           0.20    554082\n",
      "   macro avg       0.50      0.60      0.17    554082\n",
      "weighted avg       1.00      0.20      0.34    554082\n",
      "\n",
      "Area Under Curve : \n",
      " 0.5991152248360156\n"
     ]
    }
   ],
   "source": [
    "# showing results from Random Forest\n",
    "\n",
    "for measure in results:\n",
    "    print(measure,\": \\n\",results[measure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=results['Confusion Matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20483971686501276"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=r[0][0]+r[1][1]\n",
    "total=r[0][0]+r[1][1]+r[1][0]+r[0][1]\n",
    "p/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(cache_size=500,max_iter=500)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "CM_SVM = confusion_matrix(y_test,predictions)\n",
    "CR_SVM = classification_report(y_test,predictions)\n",
    "fpr, recall, thresholds = roc_curve(y_test, predictions)\n",
    "AUC_SVM = auc(fpr, recall)\n",
    "\n",
    "results = {\"Confusion Matrix\":CM_SVM,\"Classification Report\":CR_SVM,\"Area Under Curve\":AUC_SVM}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing results from Random Forest\n",
    "\n",
    "for measure in results:\n",
    "    print(measure,\": \\n\",results[measure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
