{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_layer_size, num_hidden_nodes, num_hidden_layers, output_size, lr, activation_function=\"sigmoid\", output_activation=\"\"):\n",
    "        self.alpha = lr\n",
    "        self.activation_function = activation_function\n",
    "        #i-h-h-h-o Wn = Hn+1\n",
    "        self.weight_layers = []\n",
    "        self.weight_layers.append(np.random.rand(num_hidden_nodes, input_layer_size))\n",
    "\n",
    "        for i in range(num_hidden_layers-1):\n",
    "            self.weight_layers.append(np.random.rand(num_hidden_nodes,num_hidden_nodes))\n",
    "\n",
    "        self.weight_layers.append(np.random.rand(output_size,num_hidden_nodes))\n",
    "\n",
    "        #apply xavier normalization if we're using sigmoid function\n",
    "        if self.activation_function == \"sigmoid\":\n",
    "            for layer in range(len(self.weight_layers)):\n",
    "                for n2 in range(len(self.weight_layers[layer])):\n",
    "                    fan_in = len(self.weight_layers[layer][n2])\n",
    "                    for n1 in range(len(self.weight_layers[layer][n2])):\n",
    "                        self.weight_layers[layer][n2][n1] *= np.sqrt(1.0/fan_in)\n",
    "\n",
    "        self.output_activation = output_activation\n",
    "\n",
    "\n",
    "\n",
    "        #bias nodes\n",
    "        self.biases = []\n",
    "        for hl in range(num_hidden_layers+1):\n",
    "            self.biases.append(np.zeros(num_hidden_nodes))\n",
    "\n",
    "        self.biases.append(np.zeros(output_size))\n",
    "\n",
    "    def activation(self, x, out_act=False):\n",
    "        if out_act and self.output_activation == \"softmax\":\n",
    "            osum = np.exp(x).sum()\n",
    "            return np.exp(x) / osum\n",
    "\n",
    "        if self.activation_function == \"sigmoid\":\n",
    "            exp = np.exp(x)\n",
    "            return exp / (exp + 1)\n",
    "        elif self.activation_function == \"relu\":\n",
    "            res = x\n",
    "            for i in range(len(res)):\n",
    "                res[i] = max(0,res[i])\n",
    "            return res\n",
    "        elif self.activation_function ==\"leakyrelu\":\n",
    "            res = x\n",
    "            for i in range(len(res)):\n",
    "                res[i] = max(0.01*res[i], res[i])\n",
    "            return res\n",
    "        elif self.activation_function == \"tanh\":\n",
    "            return np.tanh(x)\n",
    "\n",
    "    def activation_derivative(self, x, out_act=False):\n",
    "        if out_act and self.output_activation == \"softmax\":\n",
    "            res = self.activation(x, True)\n",
    "            return res * (1.0 - res)\n",
    "\n",
    "        if self.activation_function == \"sigmoid\":\n",
    "            sig = self.activation(x)\n",
    "            return sig * (1 - sig)\n",
    "        elif self.activation_function == \"relu\":\n",
    "            res = x\n",
    "            for i in range(len(res)):\n",
    "                if res[i] > 0:\n",
    "                    res[i] = 1\n",
    "                else:\n",
    "                    res[i] = 0\n",
    "            return res\n",
    "        elif self.activation_function == \"leakyrelu\":\n",
    "            res = x\n",
    "            for i in range(len(res)):\n",
    "                if res[i] > 0:\n",
    "                    res[i] = 1\n",
    "                else:\n",
    "                    res[i] = 0.01\n",
    "            return res\n",
    "        elif self.activation_function == \"tanh\":\n",
    "            return 1 - np.square(np.tanh(x))\n",
    "        \n",
    "\n",
    "    def feed_forward(self, input):\n",
    "        #input through hidden layers\n",
    "        self.input_layer = input\n",
    "        self.hidden_layers = []\n",
    "        self.hidden_layers.append(np.dot(self.weight_layers[0], self.input_layer))\n",
    "        for hidden_layer in range(1,len(self.weight_layers)-1):\n",
    "            self.hidden_layers.append(np.dot(self.weight_layers[hidden_layer], self.activation(self.hidden_layers[hidden_layer-1])) + self.biases[hidden_layer])\n",
    "\n",
    "        #hidden layers through output layer\n",
    "        self.output_layer = np.dot(self.weight_layers[len(self.weight_layers)-1], self.activation(self.hidden_layers[len(self.hidden_layers)-1])) + self.biases[len(self.biases)-1]\n",
    "\n",
    "        return self.activation(self.output_layer, True)\n",
    "\n",
    "    def back_propogate(self, y=[], oe=[]):\n",
    "        #error from output -> backwards\n",
    "        # BP-1\n",
    "        out_error = []\n",
    "        if len(oe) != 0 and len(y) == 0:\n",
    "            out_error = oe\n",
    "        else:\n",
    "            out_error = np.multiply((self.activation(self.output_layer, True) - y), self.activation_derivative(self.output_layer, True))\n",
    "\n",
    "        #BP-2\n",
    "        #error from output to last hidden\n",
    "        hidden_error = np.zeros([len(self.hidden_layers), len(self.hidden_layers[0])])\n",
    "        hidden_error[len(hidden_error)-1] = np.multiply(np.dot(self.weight_layers[len(self.weight_layers)-1].transpose(), out_error), self.activation_derivative(self.hidden_layers[len(self.hidden_layers)-1]))\n",
    "\n",
    "        #error from last hidden to first hidden layer\n",
    "        for i in range(len(hidden_error)-1):\n",
    "            hidden_layer = len(hidden_error) - i - 2\n",
    "            hidden_error[hidden_layer] = np.multiply(np.dot(self.weight_layers[hidden_layer+1].transpose(), hidden_error[hidden_layer+1]), self.activation_derivative(self.hidden_layers[hidden_layer]))\n",
    "\n",
    "        #adjust weights/biases wrt error\n",
    "        #in to h1\n",
    "        self.weight_layers[0] -= self.alpha * np.dot(np.reshape(hidden_error[0], (len(hidden_error[0]), -1)), np.reshape(self.activation(self.input_layer), (len(self.input_layer), -1)).transpose())\n",
    "        self.biases[0] -= self.alpha * hidden_error[0]\n",
    "\n",
    "        #h1 to hn\n",
    "        for layer in range(1, len(self.weight_layers)-1):\n",
    "            self.weight_layers[layer] -= self.alpha * (np.dot(hidden_error[layer], self.activation(self.hidden_layers[layer-1]).transpose()))\n",
    "            self.biases[layer] -= self.alpha * hidden_error[layer]\n",
    "\n",
    "        #hn to out\n",
    "        self.weight_layers[len(self.weight_layers)-1] -= self.alpha * np.dot(np.reshape(out_error, (len(out_error), -1)), np.reshape(self.activation(self.hidden_layers[len(self.hidden_layers)-1]), (len(self.hidden_layers[len(self.hidden_layers)-1]), -1)).transpose())\n",
    "        self.biases[len(self.biases)-1] -= self.alpha * out_error\n",
    "        #adjusts done\n",
    "\n",
    "    def train(self, train_data, labels, iterations, batch_size=0):\n",
    "        print(len(train_data),len(labels))\n",
    "        assert(len(train_data) == len(labels)), \"Training data and labels of different dimensions\"\n",
    "        if batch_size == 0:\n",
    "            loss = np.zeros(iterations)\n",
    "            for iteration in range(iterations):\n",
    "                for i in range(len(train_data)):\n",
    "                    self.feed_forward(train_data[i])\n",
    "                    self.back_propogate(labels[i])\n",
    "        else:\n",
    "            batch_no = np.ceil(len(train_data) / batch_size)\n",
    "            train = train_data\n",
    "            l = labels\n",
    "            for iteration in range(iterations+1):\n",
    "                train, l = self.uniform_shuffle(np.array(train), np.array(l))\n",
    "                train_batches = np.array_split(train, batch_no)\n",
    "                label_batches = np.array_split(l, batch_no)\n",
    "                for batch in range(len(train_batches)):\n",
    "                    avg_error = np.zeros(len(labels[0]))\n",
    "                    for batch_item in range(len(train_batches[batch])):\n",
    "                        self.feed_forward(train_batches[batch][batch_item])\n",
    "                        #feed into average error calculcation\n",
    "                        avg_error = avg_error + np.multiply((self.activation(self.output_layer, True) - label_batches[batch][batch_item]), self.activation_derivative(self.output_layer, True))\n",
    "                    avg_error = avg_error / batch_no\n",
    "                    self.back_propogate(oe=avg_error)\n",
    "\n",
    "    def predict(self, input):\n",
    "        return self.feed_forward(input)\n",
    "\n",
    "    #from: https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "    def uniform_shuffle(self, a, b):\n",
    "        p = np.random.permutation(len(a))\n",
    "        return a[p], b[p]\n",
    "\n",
    "    #used for testing while building the net\n",
    "    def loss_function(self, x, y):\n",
    "        if self.output_activation == \"softmax\":\n",
    "            return np.sum(-1 * y * np.log(x))\n",
    "        else:\n",
    "            return np.sum(0.5 * (x - y) ** 2) / len(x)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(df.drop('label',axis=1))\n",
    "y_train = np.array(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_size = X_train.shape[1]\n",
    "num_hidden_nodes = 8\n",
    "num_hidden_layers = 5\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_layer_size, num_hidden_nodes, num_hidden_layers, output_size, lr, activation_function, output_activation\n",
    "net = NeuralNetwork(input_layer_size, num_hidden_nodes, num_hidden_layers, output_size, 0.01, \"relu\")#, \"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000 42000\n"
     ]
    }
   ],
   "source": [
    "net.train(X_train, y_train, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel(y_test,y_pred):\n",
    "    predictionsRFR=np.array(y_pred,dtype='int') \n",
    "    CM_RFR = confusion_matrix(y_test,predictionsRFR)\n",
    "    CR_RFR = classification_report(y_test,predictionsRFR)\n",
    "    fprRFR, recallRFR, thresholdsRFR = roc_curve(y_test, predictionsRFR)\n",
    "    AUC_RFR = auc(fprRFR, recallRFR)\n",
    "    print(\"=============<>==================\\n\")\n",
    "    resultsRFR = {\"Confusion Matrix\":CM_RFR,\"Classification Report\":CR_RFR,\"Area Under Curve\":AUC_RFR}\n",
    "    for measure in resultsRFR:\n",
    "        print(measure,\": \\n\",resultsRFR[measure])\n",
    "    print(\"=============<>==================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict():\n",
    "    print(\"Predictions: \")\n",
    "    y_pred = []\n",
    "    for i in range(len(test_data)):\n",
    "        y_pred.append(net.predict(test_data[i]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[]\n",
    "y.append(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3d861059fa55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
