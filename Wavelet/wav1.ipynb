{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading needed methods\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "from random import seed,sample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score, roc_curve, auc,\\\n",
    "precision_score\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "71479e82537154fac60290ccb882f2ec1d7c778b"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('backup.csv') # unchanged dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "44dbc09b37da0a5abc23d3d15c1129ddde5ae5ea"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "eb9ae3a5fa40c19f93297aa82d405a1bd8350e63"
   },
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset,prefix=['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8213"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[dataset['isFraud']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(\"isFraud\",1)\n",
    "y = dataset.isFraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 2762196, 1: 8213})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print('Original dataset shape {}'.format(Counter(y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "import math \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pywt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-847463f1a826>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWavelet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'haar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pywt' is not defined"
     ]
    }
   ],
   "source": [
    "db1 = pywt.Wavelet('haar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dwt(X):\n",
    "    X_new = []\n",
    "    for T in X:\n",
    "        x1, x2 = np.array(pywt.dwt(T,db1))\n",
    "        v=np.append(x1,x2)\n",
    "        X_new.append(v)\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new=dwt(np.array(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new=pd.DataFrame(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new['isFraud']=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pd.read_csv('Xdwt.csv') # unchanged dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_new.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    class0_df = df[df['isFraud'] == 0] ## majority class, will be used for autoencoder training\n",
    "    class1_df = df[df['isFraud'] == 1]\n",
    "    ##\n",
    "    class0_arr = np.array(class0_df.drop('isFraud',axis = 1)) \n",
    "    class1_arr = np.array(class1_df.drop('isFraud',axis = 1))\n",
    "    X = class0_arr\n",
    "    X_train, X_test = train_test_split(X, test_size=0.1)\n",
    "    X_train, X_val = train_test_split(X_train, test_size=0.1)\n",
    "    \n",
    "    print(\"====><>>>>>\")\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    return X_train, X_val, X_test, class1_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new.to_csv('Xdwt.csv', encoding='utf-8', index = 'false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====><>>>>>\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, class1_arr = preprocess_data(X_new)\n",
    "n_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 2237378\n",
      "Val Size: 248598\n",
      "Test Size: 276220\n",
      "No of Features: 12\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Size: {}\".format(len(X_train)))\n",
    "print(\"Val Size: {}\".format(len(X_val)))\n",
    "print(\"Test Size: {}\".format(len(X_test)))\n",
    "print(\"No of Features: {}\".format(n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8213"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class1_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model archticeture\n",
    "\n",
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.Input(shape=(n_features,)),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.Dense(16, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.Dense(n_features)\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model compile\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2237378 samples, validate on 248598 samples\n",
      "Epoch 1/10\n",
      "2236416/2237378 [============================>.] - ETA: 0s - loss: 0.0812 - accuracy: 0.7971\n",
      "Epoch 00001: val_loss improved from inf to 0.01523, saving model to best_model.h5\n",
      "2237378/2237378 [==============================] - 63s 28us/sample - loss: 0.0812 - accuracy: 0.7971 - val_loss: 0.0152 - val_accuracy: 0.8199\n",
      "Epoch 2/10\n",
      "2236416/2237378 [============================>.] - ETA: 0s - loss: 0.0263 - accuracy: 0.8693\n",
      "Epoch 00002: val_loss improved from 0.01523 to 0.00764, saving model to best_model.h5\n",
      "2237378/2237378 [==============================] - 60s 27us/sample - loss: 0.0263 - accuracy: 0.8693 - val_loss: 0.0076 - val_accuracy: 0.8882\n",
      "Epoch 3/10\n",
      "2236928/2237378 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.8795\n",
      "Epoch 00003: val_loss improved from 0.00764 to 0.00568, saving model to best_model.h5\n",
      "2237378/2237378 [==============================] - 56s 25us/sample - loss: 0.0184 - accuracy: 0.8795 - val_loss: 0.0057 - val_accuracy: 0.9381\n",
      "Epoch 4/10\n",
      "2235392/2237378 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.8887\n",
      "Epoch 00004: val_loss did not improve from 0.00568\n",
      "2237378/2237378 [==============================] - 55s 25us/sample - loss: 0.0142 - accuracy: 0.8887 - val_loss: 0.0589 - val_accuracy: 0.8262\n",
      "Epoch 5/10\n",
      "2236416/2237378 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.8955\n",
      "Epoch 00005: val_loss improved from 0.00568 to 0.00333, saving model to best_model.h5\n",
      "2237378/2237378 [==============================] - 57s 26us/sample - loss: 0.0122 - accuracy: 0.8955 - val_loss: 0.0033 - val_accuracy: 0.9383\n",
      "Epoch 6/10\n",
      "2235904/2237378 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9006\n",
      "Epoch 00006: val_loss did not improve from 0.00333\n",
      "2237378/2237378 [==============================] - 56s 25us/sample - loss: 0.0105 - accuracy: 0.9006 - val_loss: 0.0055 - val_accuracy: 0.9436\n",
      "Epoch 7/10\n",
      "2235904/2237378 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.9032\n",
      "Epoch 00007: val_loss improved from 0.00333 to 0.00283, saving model to best_model.h5\n",
      "2237378/2237378 [==============================] - 57s 25us/sample - loss: 0.0094 - accuracy: 0.9032 - val_loss: 0.0028 - val_accuracy: 0.9576\n",
      "Epoch 8/10\n",
      "2236416/2237378 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.9065\n",
      "Epoch 00008: val_loss improved from 0.00283 to 0.00267, saving model to best_model.h5\n",
      "2237378/2237378 [==============================] - 58s 26us/sample - loss: 0.0084 - accuracy: 0.9065 - val_loss: 0.0027 - val_accuracy: 0.9623\n",
      "Epoch 9/10\n",
      "2235904/2237378 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9080\n",
      "Epoch 00009: val_loss did not improve from 0.00267\n",
      "2237378/2237378 [==============================] - 57s 25us/sample - loss: 0.0076 - accuracy: 0.9079 - val_loss: 0.0041 - val_accuracy: 0.8904\n",
      "Epoch 10/10\n",
      "2236928/2237378 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9095\n",
      "Epoch 00010: val_loss improved from 0.00267 to 0.00255, saving model to best_model.h5\n",
      "2237378/2237378 [==============================] - 57s 25us/sample - loss: 0.0073 - accuracy: 0.9095 - val_loss: 0.0026 - val_accuracy: 0.9326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd17c3156d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# callbacks defined\n",
    "\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 5\n",
    "    lrate = initial_lrate * (drop**((1 + epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "lrate_scheduler = LearningRateScheduler(step_decay)\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "model_chkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "# model fitting\n",
    "model.fit(X_train, X_train, batch_size=512, epochs=10, validation_data=(X_val, X_val), callbacks=[early_stop, model_chkpoint, lrate_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel(y_test,y_pred):\n",
    "    predictionsRFR=np.array(y_pred,dtype='int') \n",
    "    CM_RFR = confusion_matrix(y_test,predictionsRFR)\n",
    "    CR_RFR = classification_report(y_test,predictionsRFR)\n",
    "    fprRFR, recallRFR, thresholdsRFR = roc_curve(y_test, predictionsRFR)\n",
    "    AUC_RFR = auc(fprRFR, recallRFR)\n",
    "    print(\"=============<>==================\\n\")\n",
    "    resultsRFR = {\"Confusion Matrix\":CM_RFR,\"Classification Report\":CR_RFR,\"Area Under Curve\":AUC_RFR}\n",
    "    for measure in resultsRFR:\n",
    "        print(measure,\": \\n\",resultsRFR[measure])\n",
    "    print(\"=============<>==================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "\n",
    "\n",
    "def reconstruction_error(actual, pred):\n",
    "    return np.mean((actual - pred)**2, axis=1)\n",
    "\n",
    "def evaluate(model, X, y):\n",
    "    X = X.reshape(-1, n_features)\n",
    "    out = reconstruction_error(X, model.predict(X))\n",
    "    print(\"AUC score: {}\".format(roc_auc_score(y, out)))\n",
    "    print(\"PR score: {}\".format(average_precision_score(y, out)))\n",
    "    print(\"\\n\\n\")\n",
    "    for th in [0.5, 0.6, 0.7, 0.8, 0.9, 1., 1.1 , 1.2, 1.3, 1.4, 1.5, 1.75, 2, 2.5, 2.75, 3, 3.25, 3.5, 3.75, 4]:\n",
    "        out_th = [1 if (o > th) else 0 for o in out]\n",
    "        print(\"TH - {}\".format(th))\n",
    "        print(\"Precision: {}\".format(precision_score(y, out_th)))\n",
    "        print(\"Recall: {}\".format(recall_score(y, out_th)))\n",
    "        print(\"F1score: {}\".format(f1_score(y, out_th)))\n",
    "        rel(y,out_th)\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_test = np.concatenate((X_test, class1_arr))\n",
    "final_Y_test = np.concatenate(([0]*len(X_test), [1]*len(class1_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score: 1.0\n",
      "PR score: 1.0\n",
      "\n",
      "\n",
      "\n",
      "TH - 0.5\n",
      "Precision: 0.9927474918409284\n",
      "Recall: 1.0\n",
      "F1score: 0.9963605483440494\n",
      "=============<>==================\n",
      "\n",
      "Confusion Matrix : \n",
      " [[276160     60]\n",
      " [     0   8213]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    276220\n",
      "           1       0.99      1.00      1.00      8213\n",
      "\n",
      "    accuracy                           1.00    284433\n",
      "   macro avg       1.00      1.00      1.00    284433\n",
      "weighted avg       1.00      1.00      1.00    284433\n",
      "\n",
      "Area Under Curve : \n",
      " 0.999891390920281\n",
      "=============<>==================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TH - 0.6\n",
      "Precision: 0.9932277179828274\n",
      "Recall: 1.0\n",
      "F1score: 0.9966023540832423\n",
      "=============<>==================\n",
      "\n",
      "Confusion Matrix : \n",
      " [[276164     56]\n",
      " [     0   8213]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    276220\n",
      "           1       0.99      1.00      1.00      8213\n",
      "\n",
      "    accuracy                           1.00    284433\n",
      "   macro avg       1.00      1.00      1.00    284433\n",
      "weighted avg       1.00      1.00      1.00    284433\n",
      "\n",
      "Area Under Curve : \n",
      " 0.9998986315255955\n",
      "=============<>==================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TH - 0.7\n",
      "Precision: 0.9941895654279143\n",
      "Recall: 1.0\n",
      "F1score: 0.9970863178341629\n",
      "=============<>==================\n",
      "\n",
      "Confusion Matrix : \n",
      " [[276172     48]\n",
      " [     0   8213]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    276220\n",
      "           1       0.99      1.00      1.00      8213\n",
      "\n",
      "    accuracy                           1.00    284433\n",
      "   macro avg       1.00      1.00      1.00    284433\n",
      "weighted avg       1.00      1.00      1.00    284433\n",
      "\n",
      "Area Under Curve : \n",
      " 0.9999131127362247\n",
      "=============<>==================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TH - 0.8\n",
      "Precision: 0.9951532775960257\n",
      "Recall: 1.0\n",
      "F1score: 0.9975707518523017\n",
      "=============<>==================\n",
      "\n",
      "Confusion Matrix : \n",
      " [[276180     40]\n",
      " [     0   8213]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    276220\n",
      "           1       1.00      1.00      1.00      8213\n",
      "\n",
      "    accuracy                           1.00    284433\n",
      "   macro avg       1.00      1.00      1.00    284433\n",
      "weighted avg       1.00      1.00      1.00    284433\n",
      "\n",
      "Area Under Curve : \n",
      " 0.9999275939468539\n",
      "=============<>==================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TH - 0.9\n",
      "Precision: 0.9955151515151515\n",
      "Recall: 1.0\n",
      "F1score: 0.9977525359897953\n",
      "=============<>==================\n",
      "\n",
      "Confusion Matrix : \n",
      " [[276183     37]\n",
      " [     0   8213]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    276220\n",
      "           1       1.00      1.00      1.00      8213\n",
      "\n",
      "    accuracy                           1.00    284433\n",
      "   macro avg       1.00      1.00      1.00    284433\n",
      "weighted avg       1.00      1.00      1.00    284433\n",
      "\n",
      "Area Under Curve : \n",
      " 0.99993302440084\n",
      "=============<>==================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TH - 1.0\n",
      "Precision: 0.9959980596652923\n",
      "Recall: 1.0\n",
      "F1score: 0.9979950179233246\n",
      "=============<>==================\n",
      "\n",
      "Confusion Matrix : \n",
      " [[276187     33]\n",
      " [     0   8213]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    276220\n",
      "           1       1.00      1.00      1.00      8213\n",
      "\n",
      "    accuracy                           1.00    284433\n",
      "   macro avg       1.00      1.00      1.00    284433\n",
      "weighted avg       1.00      1.00      1.00    284433\n",
      "\n",
      "Area Under Curve : \n",
      " 0.9999402650061545\n",
      "=============<>==================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TH - 1.1\n",
      "Precision: 0.996481436544528\n",
      "Recall: 1.0\n",
      "F1score: 0.9982376177453661\n",
      "=============<>==================\n",
      "\n",
      "Confusion Matrix : \n",
      " [[276191     29]\n",
      " [     0   8213]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    276220\n",
      "           1       1.00      1.00      1.00      8213\n",
      "\n",
      "    accuracy                           1.00    284433\n",
      "   macro avg       1.00      1.00      1.00    284433\n",
      "weighted avg       1.00      1.00      1.00    284433\n",
      "\n",
      "Area Under Curve : \n",
      " 0.9999475056114691\n",
      "=============<>==================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TH - 1.2\n",
      "Precision: 0.9966023540832423\n",
      "Recall: 1.0\n",
      "F1score: 0.9982982861310319\n",
      "=============<>==================\n",
      "\n",
      "Confusion Matrix : \n",
      " [[276192     28]\n",
      " [     0   8213]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    276220\n",
      "           1       1.00      1.00      1.00      8213\n",
      "\n",
      "    accuracy                           1.00    284433\n",
      "   macro avg       1.00      1.00      1.00    284433\n",
      "weighted avg       1.00      1.00      1.00    284433\n",
      "\n",
      "Area Under Curve : \n",
      " 0.9999493157627978\n",
      "=============<>==================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TH - 1.3\n",
      "Precision: 0.9972073822243808\n",
      "Recall: 1.0\n",
      "F1score: 0.9986017387075202\n",
      "=============<>==================\n",
      "\n",
      "Confusion Matrix : \n",
      " [[276197     23]\n",
      " [     0   8213]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    276220\n",
      "           1       1.00      1.00      1.00      8213\n",
      "\n",
      "    accuracy                           1.00    284433\n",
      "   macro avg       1.00      1.00      1.00    284433\n",
      "weighted avg       1.00      1.00      1.00    284433\n",
      "\n",
      "Area Under Curve : \n",
      " 0.999958366519441\n",
      "=============<>==================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TH - 1.4\n",
      "Precision: 0.9973284760170006\n",
      "Recall: 1.0\n",
      "F1score: 0.9986624513618677\n",
      "=============<>==================\n",
      "\n",
      "Confusion Matrix : \n",
      " [[276198     22]\n",
      " [     0   8213]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    276220\n",
      "           1       1.00      1.00      1.00      8213\n",
      "\n",
      "    accuracy                           1.00    284433\n",
      "   macro avg       1.00      1.00      1.00    284433\n",
      "weighted avg       1.00      1.00      1.00    284433\n",
      "\n",
      "Area Under Curve : \n",
      " 0.9999601766707698\n",
      "=============<>==================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TH - 1.5\n",
      "Precision: 0.997449599222735\n",
      "Recall: 1.0\n",
      "F1score: 0.9987231713990393\n",
      "=============<>==================\n",
      "\n",
      "Confusion Matrix : \n",
      " [[276199     21]\n",
      " [     0   8213]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    276220\n",
      "           1       1.00      1.00      1.00      8213\n",
      "\n",
      "    accuracy                           1.00    284433\n",
      "   macro avg       1.00      1.00      1.00    284433\n",
      "weighted avg       1.00      1.00      1.00    284433\n",
      "\n",
      "Area Under Curve : \n",
      " 0.9999619868220982\n",
      "=============<>==================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TH - 1.75\n",
      "Precision: 0.9978131454258292\n",
      "Recall: 1.0\n",
      "F1score: 0.9989053758209682\n",
      "=============<>==================\n",
      "\n",
      "Confusion Matrix : \n",
      " [[276202     18]\n",
      " [     0   8213]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    276220\n",
      "           1       1.00      1.00      1.00      8213\n",
      "\n",
      "    accuracy                           1.00    284433\n",
      "   macro avg       1.00      1.00      1.00    284433\n",
      "weighted avg       1.00      1.00      1.00    284433\n",
      "\n",
      "Area Under Curve : \n",
      " 0.9999674172760843\n",
      "=============<>==================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TH - 2\n",
      "Precision: 0.9980556568234293\n",
      "Recall: 1.0\n",
      "F1score: 0.999026882374407\n",
      "=============<>==================\n",
      "\n",
      "Confusion Matrix : \n",
      " [[276204     16]\n",
      " [     0   8213]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    276220\n",
      "           1       1.00      1.00      1.00      8213\n",
      "\n",
      "    accuracy                           1.00    284433\n",
      "   macro avg       1.00      1.00      1.00    284433\n",
      "weighted avg       1.00      1.00      1.00    284433\n",
      "\n",
      "Area Under Curve : \n",
      " 0.9999710375787415\n",
      "=============<>==================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TH - 2.5\n",
      "Precision: 0.9985410334346505\n",
      "Recall: 1.0\n",
      "F1score: 0.9992699841829906\n",
      "=============<>==================\n",
      "\n",
      "Confusion Matrix : \n",
      " [[276208     12]\n",
      " [     0   8213]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    276220\n",
      "           1       1.00      1.00      1.00      8213\n",
      "\n",
      "    accuracy                           1.00    284433\n",
      "   macro avg       1.00      1.00      1.00    284433\n",
      "weighted avg       1.00      1.00      1.00    284433\n",
      "\n",
      "Area Under Curve : \n",
      " 0.9999782781840563\n",
      "=============<>==================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TH - 2.75\n",
      "Precision: 0.9986624513618677\n",
      "Recall: 1.0\n",
      "F1score: 0.9993307781225284\n",
      "=============<>==================\n",
      "\n",
      "Confusion Matrix : \n",
      " [[276209     11]\n",
      " [     0   8213]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    276220\n",
      "           1       1.00      1.00      1.00      8213\n",
      "\n",
      "    accuracy                           1.00    284433\n",
      "   macro avg       1.00      1.00      1.00    284433\n",
      "weighted avg       1.00      1.00      1.00    284433\n",
      "\n",
      "Area Under Curve : \n",
      " 0.9999800883353848\n",
      "=============<>==================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TH - 3\n",
      "Precision: 0.9986624513618677\n",
      "Recall: 1.0\n",
      "F1score: 0.9993307781225284\n",
      "=============<>==================\n",
      "\n",
      "Confusion Matrix : \n",
      " [[276209     11]\n",
      " [     0   8213]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    276220\n",
      "           1       1.00      1.00      1.00      8213\n",
      "\n",
      "    accuracy                           1.00    284433\n",
      "   macro avg       1.00      1.00      1.00    284433\n",
      "weighted avg       1.00      1.00      1.00    284433\n",
      "\n",
      "Area Under Curve : \n",
      " 0.9999800883353848\n",
      "=============<>==================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TH - 3.25\n",
      "Precision: 0.9986624513618677\n",
      "Recall: 1.0\n",
      "F1score: 0.9993307781225284\n",
      "=============<>==================\n",
      "\n",
      "Confusion Matrix : \n",
      " [[276209     11]\n",
      " [     0   8213]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    276220\n",
      "           1       1.00      1.00      1.00      8213\n",
      "\n",
      "    accuracy                           1.00    284433\n",
      "   macro avg       1.00      1.00      1.00    284433\n",
      "weighted avg       1.00      1.00      1.00    284433\n",
      "\n",
      "Area Under Curve : \n",
      " 0.9999800883353848\n",
      "=============<>==================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TH - 3.5\n",
      "Precision: 0.9986624513618677\n",
      "Recall: 1.0\n",
      "F1score: 0.9993307781225284\n",
      "=============<>==================\n",
      "\n",
      "Confusion Matrix : \n",
      " [[276209     11]\n",
      " [     0   8213]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    276220\n",
      "           1       1.00      1.00      1.00      8213\n",
      "\n",
      "    accuracy                           1.00    284433\n",
      "   macro avg       1.00      1.00      1.00    284433\n",
      "weighted avg       1.00      1.00      1.00    284433\n",
      "\n",
      "Area Under Curve : \n",
      " 0.9999800883353848\n",
      "=============<>==================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TH - 3.75\n",
      "Precision: 0.9986624513618677\n",
      "Recall: 1.0\n",
      "F1score: 0.9993307781225284\n",
      "=============<>==================\n",
      "\n",
      "Confusion Matrix : \n",
      " [[276209     11]\n",
      " [     0   8213]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    276220\n",
      "           1       1.00      1.00      1.00      8213\n",
      "\n",
      "    accuracy                           1.00    284433\n",
      "   macro avg       1.00      1.00      1.00    284433\n",
      "weighted avg       1.00      1.00      1.00    284433\n",
      "\n",
      "Area Under Curve : \n",
      " 0.9999800883353848\n",
      "=============<>==================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TH - 4\n",
      "Precision: 0.9987838988203819\n",
      "Recall: 1.0\n",
      "F1score: 0.9993915794597226\n",
      "=============<>==================\n",
      "\n",
      "Confusion Matrix : \n",
      " [[276210     10]\n",
      " [     0   8213]]\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    276220\n",
      "           1       1.00      1.00      1.00      8213\n",
      "\n",
      "    accuracy                           1.00    284433\n",
      "   macro avg       1.00      1.00      1.00    284433\n",
      "weighted avg       1.00      1.00      1.00    284433\n",
      "\n",
      "Area Under Curve : \n",
      " 0.9999818984867135\n",
      "=============<>==================\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "evaluate(model, final_X_test, final_Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "out = reconstruction_error(final_X_test, model.predict(final_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAATiElEQVR4nO3df5BdZ33f8fcH/Yj4IWMiCXAkOxLUhIgMJmQxhCFFJCW2TFOFlGZsMnHrCfW4wUmY/mOXSUI6zkyhCRPiwUTVUMeBiaM24AGRChxSfqUBxZZbY1t2DBvbWBubei0TxwgcI/vbP+4VXN+9K11Je+5293m/ZnbmPuc8e+730WrO5z7nnHtOqgpJUruesdgFSJIWl0EgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQaNlJcl+Sbyf5ZpKvJ7kuyXOG+rw2yWeSPJbk0SSfSLJ1qM9pSd6X5P7+tqb77fWTHZHULYNAy9XPVNVzgFcAPwr8h6Mrkvw48OfAx4EfALYAXwb+KsmL+n1WA/8TeBlwPnAa8FrgEHBuV0UnWdnVtqX5GARa1qrq68CN9ALhqP8MfKiqfr+qHquqR6rq14F9wG/1+1wMnAW8uarurKqnquqhqrqqqvaOeq8kL0vy6SSPJPm/Sd7ZX35dkt8e6LctycxA+74kVyS5DTic5NeTfGRo27+f5Or+6+cm+a9JHkzyd0l+O8mKU/uXUssMAi1rSTYB24HpfvtZ9D7Z/+mI7v8deGP/9T8DPlVV3xzzfdYCfwF8it4s45/Qm1GM6yLgTcDpwIeBC5Kc1t/2CuDngev7ff8IONJ/jx8Ffhp42wm8l/Q0BoGWq48leQw4CDwEvKu//Pvp/b9/cMTvPAgcPf6/bp4+8/nnwNer6r1V9Xh/pvHXJ/D7V1fVwar6dlV9DfjfwM/21/0k8K2q2pfkBfSC7R1VdbiqHgJ+D7jwBN5LehqDQMvVz1bVWmAb8FK+t4P/BvAUcMaI3zkDeLj/+tA8feZzJvC3J1Vpz8Gh9vX0ZgkAb+V7s4EfBFYBDyb5+yR/D/wX4Pmn8N5qnEGgZa2qPg9cB/xuv30Y+BLwr0Z0/3m+dzjnL4Dzkjx7zLc6CLx4nnWHgWcNtF84qtSh9p8C2/qHtt7M94LgIPCPwPqqOr3/c1pVvWzMOqU5DAK14H3AG5O8ot++EvjXSX41ydokz+ufzP1x4D/2+3yY3k73o0lemuQZSdYleWeSC0a8x58BL0zyjiTf19/uq/vrbqV3zP/7k7wQeMfxCq6qWeBzwB8C91bVXf3lD9K74um9/ctbn5HkxUlef4L/JtJ3GQRa9vo71Q8Bv9Fv/y/gPODn6J0H+Bq9k66vq6qv9vv8I70Txn8DfBr4B+AmeoeY5hz7r6rH6J1o/hng68BXgTf0V3+Y3uWp99Hbif+3MUu/vl/D9UPLLwZWA3fSO9T1EU7sMJb0NPHBNJLUNmcEktQ4g0CSGmcQSFLjDAJJatySu8HV+vXra/PmzYtdhiQtKbfccsvDVbVh1LolFwSbN29m//79i12GJC0pSb423zoPDUlS4wwCSWqcQSBJjVty5wgkqXXf+c53mJmZ4fHHH5+zbs2aNWzatIlVq1aNvT2DQJKWmJmZGdauXcvmzZtJ8t3lVcWhQ4eYmZlhy5YtY2+vs0NDSa5N8lCSO+ZZnyRX9x8IfluSV3ZViyQtJ48//jjr1q17WggAJGHdunUjZwrH0uU5guvoPfR7PtuBs/s/lwJ/0GEtkrSsDIfA8ZYfS2eHhqrqC0k2H6PLDnoPEC9gX5LTk5zRv9/6grvkD2/is3fPdrFpSZqY+979pgXf5mJeNbSRpz+eb6a/bI4klybZn2T/7OzJ7cwNAUkabTFPFo+av4x8OEJV7QJ2AUxNTZ3SAxS6SFNJmrSqGnkY6GSeMbOYM4IZeg/8PmoT8MAi1SJJS8aaNWs4dOjQnJ3+0auG1qxZc0LbW8wZwR7g8iS7gVcDj3Z1fkCSlpNNmzYxMzPDqEPlR79HcCI6C4IkfwJsA9YnmQHeBawCqKqdwF7gAmAa+BZwSVe1SNJysmrVqhP6nsDxdHnV0EXHWV/A27t6f0nSeLzXkCQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjes0CJKcn+TuJNNJrhyx/rlJPpHky0kOJLmky3okSXN1FgRJVgDXANuBrcBFSbYOdXs7cGdVnQNsA96bZHVXNUmS5upyRnAuMF1V91TVE8BuYMdQnwLWJgnwHOAR4EiHNUmShnQZBBuBgwPtmf6yQe8Hfhh4ALgd+LWqemp4Q0kuTbI/yf7Z2dmu6pWkJnUZBBmxrIba5wG3Aj8AvAJ4f5LT5vxS1a6qmqqqqQ0bNix0nZLUtC6DYAY4c6C9id4n/0GXADdUzzRwL/DSDmuSJA3pMghuBs5OsqV/AvhCYM9Qn/uBnwJI8gLgh4B7OqxJkjRkZVcbrqojSS4HbgRWANdW1YEkl/XX7wSuAq5Lcju9Q0lXVNXDXdUkSZqrsyAAqKq9wN6hZTsHXj8A/HSXNUiSjs1vFktS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGdRoESc5PcneS6SRXztNnW5JbkxxI8vku65EkzbWyqw0nWQFcA7wRmAFuTrKnqu4c6HM68AHg/Kq6P8nzu6pHkjRalzOCc4Hpqrqnqp4AdgM7hvq8Fbihqu4HqKqHOqxHkjRCl0GwETg40J7pLxv0EuB5ST6X5JYkF4/aUJJLk+xPsn92drajciWpTV0GQUYsq6H2SuDHgDcB5wG/keQlc36paldVTVXV1IYNGxa+UklqWGfnCOjNAM4caG8CHhjR5+GqOgwcTvIF4BzgKx3WJUka0OWM4Gbg7CRbkqwGLgT2DPX5OPATSVYmeRbwauCuDmuSJA3pbEZQVUeSXA7cCKwArq2qA0ku66/fWVV3JfkUcBvwFPDBqrqjq5okSXN1eWiIqtoL7B1atnOo/TvA73RZhyRpfn6zWJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGnfMIEjyjCSvnVQxkqTJO2YQVNVTwHsnVIskaRGMc2joz5P8yySjni8gSVrixrnp3L8Hng08meTb9B44U1V1WqeVSZIm4rhBUFVrJ1GIJGlxjHUb6iQ/B7yO3qMm/7KqPtZlUZKkyTnuOYIkHwAuA24H7gAuS3JN14VJkiZjnBnB64EfqaoCSPJH9EJBkrQMjHPV0N3AWQPtM+k9WlKStAyMMyNYB9yV5KZ++1XAl5LsAaiqf9FVcZKk7o0TBM8Etg+0A7wHuKqTiiRJEzVOEKysqs8PLkjyzOFlkqSlad4gSPLvgF8GXpRk8JzAWuCvui5MkjQZx5oRXA98EvhPwJUDyx+rqkc6rUqSNDHzBkFVPQo8Clw0uXIkSZPm8wgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWpcp0GQ5PwkdyeZTnLlMfq9KsmTSd7SZT2SpLk6C4IkK4Br6N2wbitwUZKt8/R7D3BjV7VIkubX5YzgXGC6qu6pqieA3cCOEf1+Bfgo8FCHtUiS5tFlEGwEDg60Z/rLvivJRuDNwM5jbSjJpUn2J9k/Ozu74IVKUsu6DIKMWFZD7fcBV1TVk8faUFXtqqqpqprasGHDQtUnSWK85xGcrBl6j7U8ahPwwFCfKWB3EoD1wAVJjlTVxzqsS5I0oMsguBk4O8kW4O+AC4G3Dnaoqi1HXye5DvgzQ0CSJquzIKiqI0kup3c10Arg2qo6kOSy/vpjnheQJE1GlzMCqmovsHdo2cgAqKp/02UtkqTR/GaxJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJalynQZDk/CR3J5lOcuWI9b+Q5Lb+zxeTnNNlPZKkuToLgiQrgGuA7cBW4KIkW4e63Qu8vqpeDlwF7OqqHknSaF3OCM4Fpqvqnqp6AtgN7BjsUFVfrKpv9Jv7gE0d1iNJGqHLINgIHBxoz/SXzeeXgE+OWpHk0iT7k+yfnZ1dwBIlSV0GQUYsq5EdkzfQC4IrRq2vql1VNVVVUxs2bFjAEiVJKzvc9gxw5kB7E/DAcKckLwc+CGyvqkMd1iNJGqHLGcHNwNlJtiRZDVwI7BnskOQs4AbgF6vqKx3WIkmaR2czgqo6kuRy4EZgBXBtVR1Icll//U7gN4F1wAeSABypqqmuapIkzdXloSGqai+wd2jZzoHXbwPe1mUNkqRj85vFktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1rtMgSHJ+kruTTCe5csT6JLm6v/62JK/ssh5J0lydBUGSFcA1wHZgK3BRkq1D3bYDZ/d/LgX+oKt6JEmjdTkjOBeYrqp7quoJYDewY6jPDuBD1bMPOD3JGR3WJEka0mUQbAQODrRn+stOtA9JLk2yP8n+2dnZBS9Uklq2ssNtZ8SyOok+VNUuYBfA1NTUnPXjuO/dbzqZX5OkZa/LGcEMcOZAexPwwEn0kSR1qMsguBk4O8mWJKuBC4E9Q332ABf3rx56DfBoVT3YYU2SpCGdHRqqqiNJLgduBFYA11bVgSSX9dfvBPYCFwDTwLeAS7qqR5I0WpfnCKiqvfR29oPLdg68LuDtXdYgSTo2v1ksSY0zCCSpcQaBJDXOIJCkxqV3vnbpSDILfO0kf3098PAClrMUOOY2OOY2nMqYf7CqNoxaseSC4FQk2V9VU4tdxyQ55jY45jZ0NWYPDUlS4wwCSWpca0Gwa7ELWASOuQ2OuQ2djLmpcwSSpLlamxFIkoYYBJLUuGUZBEnOT3J3kukkV45YnyRX99ffluSVi1HnQhpjzL/QH+ttSb6Y5JzFqHMhHW/MA/1eleTJJG+ZZH1dGGfMSbYluTXJgSSfn3SNC22M/9vPTfKJJF/uj3lJ38U4ybVJHkpyxzzrF37/VVXL6ofeLa//FngRsBr4MrB1qM8FwCfpPSHtNcBfL3bdExjza4Hn9V9vb2HMA/0+Q+8uuG9Z7Lon8Hc+HbgTOKvffv5i1z2BMb8TeE//9QbgEWD1Ytd+CmP+p8ArgTvmWb/g+6/lOCM4F5iuqnuq6glgN7BjqM8O4EPVsw84PckZky50AR13zFX1xar6Rr+5j97T4Jaycf7OAL8CfBR4aJLFdWScMb8VuKGq7geoqqU+7nHGXMDaJAGeQy8Ijky2zIVTVV+gN4b5LPj+azkGwUbg4EB7pr/sRPssJSc6nl+i94liKTvumJNsBN4M7GR5GOfv/BLgeUk+l+SWJBdPrLpujDPm9wM/TO8xt7cDv1ZVT02mvEWx4PuvTh9Ms0gyYtnwNbLj9FlKxh5PkjfQC4LXdVpR98YZ8/uAK6rqyd6HxSVvnDGvBH4M+CngmcCXkuyrqq90XVxHxhnzecCtwE8CLwY+neQvq+ofOq5tsSz4/ms5BsEMcOZAexO9Twon2mcpGWs8SV4OfBDYXlWHJlRbV8YZ8xSwux8C64ELkhypqo9NpMKFN+7/7Yer6jBwOMkXgHOApRoE44z5EuDd1TuAPp3kXuClwE2TKXHiFnz/tRwPDd0MnJ1kS5LVwIXAnqE+e4CL+2ffXwM8WlUPTrrQBXTcMSc5C7gB+MUl/Olw0HHHXFVbqmpzVW0GPgL88hIOARjv//bHgZ9IsjLJs4BXA3dNuM6FNM6Y76c3AyLJC4AfAu6ZaJWTteD7r2U3I6iqI0kuB26kd8XBtVV1IMll/fU76V1BcgEwDXyL3ieKJWvMMf8msA74QP8T8pFawnduHHPMy8o4Y66qu5J8CrgNeAr4YFWNvAxxKRjz73wVcF2S2+kdNrmiqpbs7amT/AmwDVifZAZ4F7AKutt/eYsJSWrccjw0JEk6AQaBJDXOIJCkxhkEktQ4g0CSGmcQSCchya8muSvJHy92LdKp8vJR6SQk+Rt639C+d4y+K6rqyQmUJZ0UZwTSCUqyk95tkfckeTTJh5N8JslXk/zbfp9tST6b5Hp6N0KT/r/ljEA6CUnuo3cvo8vp3eH0NcCzgf9D77YOLwH+B/Aj48wapMXkjEA6dR+vqm/3b2vwWXr30Ae4yRDQUmAQSKdueFp9tH140oVIJ8MgkE7djiRrkqyjd7Owmxe5HumEGATSqbuJ3vmAfcBVVbWUn22hBnmyWDoFSX4L+GZV/e5i1yKdLGcEktQ4ZwSS1DhnBJLUOINAkhpnEEhS4wwCSWqcQSBJjft/YXF2EyfrmBQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, _ = roc_curve(final_Y_test, out)\n",
    "                        \n",
    "plt.plot(fpr, tpr, lw=2)\n",
    "    \n",
    "plt.xlabel(\"fpr\")\n",
    "plt.ylabel(\"tpr\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"ROC curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
